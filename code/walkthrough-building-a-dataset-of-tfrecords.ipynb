{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction #\n\nIn this notebook we'll go through a start-to-finish example of building a dataset of TFRecords. To read the image files, we'll use a Keras dataset constructor new in TF2.3. You could read the data another way, if you like, but this simplifies some of the preprocessing.","metadata":{}},{"cell_type":"code","source":"# tf.keras.preprocessing.image_dataset_from_directory will be available in TF2.3\n!pip install -q tf-nightly\n\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:47:16.326097Z","iopub.execute_input":"2022-02-23T19:47:16.326434Z","iopub.status.idle":"2022-02-23T19:47:26.024715Z","shell.execute_reply.started":"2022-02-23T19:47:16.326387Z","shell.execute_reply":"2022-02-23T19:47:26.023457Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Image Data #","metadata":{}},{"cell_type":"code","source":"import pathlib\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file(origin=dataset_url, \n                                   fname='flower_photos', \n                                   untar=True,\n                                   cache_dir=\"/kaggle/working/downloaded\")\ndata_dir = pathlib.Path(data_dir)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-02-23T19:50:46.174978Z","iopub.execute_input":"2022-02-23T19:50:46.175335Z","iopub.status.idle":"2022-02-23T19:50:46.744466Z","shell.execute_reply.started":"2022-02-23T19:50:46.175288Z","shell.execute_reply":"2022-02-23T19:50:46.743149Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\nIMG_HEIGHT = 512\nIMG_WIDTH = 512\n\nload_split = partial(\n    tf.keras.preprocessing.image_dataset_from_directory,\n    data_dir,\n    validation_split=0.2,\n    shuffle=True,\n    seed=123,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=1,\n)\n\nds_train = load_split(subset='training')\nds_valid = load_split(subset='validation')\n\nclass_names = ds_train.class_names\nprint(\"\\nClass names: {}\".format(class_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wrap with tf.Example #","metadata":{}},{"cell_type":"code","source":"from tensorflow.train import BytesList, FloatList, Int64List\nfrom tensorflow.train import Example, Features, Feature\n\ndef process_image(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n    image = tf.io.encode_jpeg(image)\n    return image, label\n\nds_train_encoded = (\n    ds_train\n    .unbatch()\n    .map(process_image)\n)\n\nds_valid_encoded = (\n    ds_valid\n    .unbatch()\n    .map(process_image)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_example(encoded_image, label):\n    image_feature = Feature(\n        bytes_list=BytesList(value=[\n            encoded_image,\n        ]),\n    )\n    label_feature = Feature(\n        int64_list=Int64List(value=[\n            label,\n        ])\n    )\n\n    features = Features(feature={\n        'image': image_feature,\n        'label': label_feature,\n    })\n    \n    example = Example(features=features)\n    \n    return example.SerializeToString()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To shard the dataset, we'll use `tf.data.Datset.shard`. We'll write the TFRecords by iterating shard by shard in an outer loop and within each shard in an inner loop. For TPU training, you'll want at least 8 shards for each split. First the training set:","metadata":{}},{"cell_type":"code","source":"!mkdir '/kaggle/working/training'\n\nNUM_SHARDS = 32\nPATH = '/kaggle/working/training/shard_{:02d}.tfrecord'\n\nfor shard in range(NUM_SHARDS):\n    ds_shard = (\n        ds_train_encoded\n        .shard(NUM_SHARDS, shard)\n        .as_numpy_iterator()\n    )\n    with tf.io.TFRecordWriter(path=PATH.format(shard)) as f:\n        for encoded_image, label in ds_shard:\n            example = make_example(encoded_image, label)\n            f.write(example)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the validation set:","metadata":{}},{"cell_type":"code","source":"!mkdir '/kaggle/working/validation'\n\nNUM_SHARDS = 8\nPATH = '/kaggle/working/validation/shard_{:02d}.tfrecord'\n\nfor shard in range(NUM_SHARDS):\n    ds_shard = (\n        ds_valid_encoded\n        .shard(NUM_SHARDS, shard)\n        .as_numpy_iterator()\n    )\n    with tf.io.TFRecordWriter(path=PATH.format(shard)) as f:\n        for encoded_image, label in ds_shard:\n            example = make_example(encoded_image, label)\n            f.write(example)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we'll clean up the downloaded files.","metadata":{}},{"cell_type":"code","source":"!rm -rf '/kaggle/working/downloaded'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If the dataset isn't too big, you could build the TFRecords within a notebook here on Kaggle and create a new dataset directly from the notebook. (Do *Save Version*, *Save & Run All*, and then create a new dataset from the notebook output.) For larger datasets, you could either run it on a personal machine or upgrade to a Cloud AI notebook. (See the option in the *File* menu.)","metadata":{}}]}