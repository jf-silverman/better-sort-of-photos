{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In this notebook we'll go through a start-to-finish example of building a dataset of TFRecords. To read the image files, we'll use a Keras dataset constructor new in TF2.3. You could read the data another way, if you like, but this simplifies some of the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.image_dataset_from_directory will be available in TF2.3\n",
    "!pip install -q tf-nightly\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
    "                                   fname='flower_photos', \n",
    "                                   untar=True,\n",
    "                                   cache_dir=\"/kaggle/working/downloaded\")\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n",
      "\n",
      "Class names: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 08:29:45.243530: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "\n",
    "load_split = partial(\n",
    "    tf.keras.preprocessing.image_dataset_from_directory,\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "ds_train = load_split(subset='training')\n",
    "ds_valid = load_split(subset='validation')\n",
    "\n",
    "class_names = ds_train.class_names\n",
    "print(\"\\nClass names: {}\".format(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap with tf.Example #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "\n",
    "def process_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n",
    "    image = tf.io.encode_jpeg(image)\n",
    "    return image, label\n",
    "\n",
    "ds_train_encoded = (\n",
    "    ds_train\n",
    "    .unbatch()\n",
    "    .map(process_image)\n",
    ")\n",
    "\n",
    "ds_valid_encoded = (\n",
    "    ds_valid\n",
    "    .unbatch()\n",
    "    .map(process_image)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_example(encoded_image, label):\n",
    "    image_feature = Feature(\n",
    "        bytes_list=BytesList(value=[\n",
    "            encoded_image,\n",
    "        ]),\n",
    "    )\n",
    "    label_feature = Feature(\n",
    "        int64_list=Int64List(value=[\n",
    "            label,\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    features = Features(feature={\n",
    "        'image': image_feature,\n",
    "        'label': label_feature,\n",
    "    })\n",
    "    \n",
    "    example = Example(features=features)\n",
    "    \n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shard the dataset, we'll use `tf.data.Datset.shard`. We'll write the TFRecords by iterating shard by shard in an outer loop and within each shard in an inner loop. For TPU training, you'll want at least 8 shards for each split. First the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /kaggle/working: No such file or directory\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/kaggle/working/training/shard_00.tfrecord; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m1/lw85csd9051bvbz6qyj0mnpm0000gn/T/ipykernel_28950/2788142285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencoded_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_shard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, options)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m     super(TFRecordWriter, self).__init__(\n\u001b[0m\u001b[1;32m    295\u001b[0m         compat.as_bytes(path), options._as_record_writer_options())\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /kaggle/working/training/shard_00.tfrecord; No such file or directory"
     ]
    }
   ],
   "source": [
    "!mkdir '/kaggle/working/training'\n",
    "\n",
    "NUM_SHARDS = 32\n",
    "PATH = '/kaggle/working/training/shard_{:02d}.tfrecord'\n",
    "\n",
    "for shard in range(NUM_SHARDS):\n",
    "    ds_shard = (\n",
    "        ds_train_encoded\n",
    "        .shard(NUM_SHARDS, shard)\n",
    "        .as_numpy_iterator()\n",
    "    )\n",
    "    with tf.io.TFRecordWriter(path=PATH.format(shard)) as f:\n",
    "        for encoded_image, label in ds_shard:\n",
    "            example = make_example(encoded_image, label)\n",
    "            f.write(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '/kaggle/working/validation'\n",
    "\n",
    "NUM_SHARDS = 8\n",
    "PATH = '/kaggle/working/validation/shard_{:02d}.tfrecord'\n",
    "\n",
    "for shard in range(NUM_SHARDS):\n",
    "    ds_shard = (\n",
    "        ds_valid_encoded\n",
    "        .shard(NUM_SHARDS, shard)\n",
    "        .as_numpy_iterator()\n",
    "    )\n",
    "    with tf.io.TFRecordWriter(path=PATH.format(shard)) as f:\n",
    "        for encoded_image, label in ds_shard:\n",
    "            example = make_example(encoded_image, label)\n",
    "            f.write(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll clean up the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '/kaggle/working/downloaded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset isn't too big, you could build the TFRecords within a notebook here on Kaggle and create a new dataset directly from the notebook. (Do *Save Version*, *Save & Run All*, and then create a new dataset from the notebook output.) For larger datasets, you could either run it on a personal machine or upgrade to a Cloud AI notebook. (See the option in the *File* menu.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
