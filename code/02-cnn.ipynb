{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8734705c-b5d4-49da-85c5-6e011ae15ed5",
   "metadata": {},
   "source": [
    "# Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7cd54-edcd-43ae-aff0-8a758a213c91",
   "metadata": {},
   "source": [
    "**Source reference material for this notebook include:\n",
    "GA DSI Lecture Notebooks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "descending-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "critical-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-flexibility",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Importing the data\n",
    "\n",
    "The code below will do the following:\n",
    "\n",
    "- Create a list to store array representations of images from a given class\n",
    "- Convert the array to a normalized representation\n",
    "- Store the normalized array\n",
    "- Print an error message for files that could not be converted\n",
    "- Convert the lists to a numpy array representation for compatibility with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "recognized-truck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "good_arrays = []\n",
    "# define filepath for Dog class\n",
    "good_path = '../data/yelp_mex_food_pics/good/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "for file in os.listdir(good_path):\n",
    "    try:\n",
    "        # target_size automatically resizes each img on import\n",
    "        good = load_img(good_path + file, target_size=(348, 348))\n",
    "        good_arr = img_to_array(good) / 347\n",
    "        good_arrays.append(good_arr)\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "\n",
    "print(f'{len(good_arrays)} pictures converted.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "subtle-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "bad_arrays = []\n",
    "# define filepath for bad class\n",
    "bad_path = '../data/yelp_mex_food_pics/bad/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "for file in os.listdir(bad_path):\n",
    "    try:\n",
    "        bad = load_img(bad_path + file, target_size=(348, 348))\n",
    "        bad_arr = img_to_array(bad) / 347\n",
    "        bad_arrays.append(bad_arr)\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "    \n",
    "print(f'{len(bad_arrays)} pictures converted.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf2c1ad2-247e-430b-ae69-e185d42ccd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1018, 348, 348, 3)\n",
      "y shape: (1018,)\n"
     ]
    }
   ],
   "source": [
    "# X should contain both bad and good\n",
    "X = good_arrays + bad_arrays\n",
    "\n",
    "# convert to array and check shape\n",
    "X_arr = np.array(X)\n",
    "print(f'X shape: {X_arr.shape}')\n",
    "\n",
    "# 1 for good, 0 for bad\n",
    "y = [1] * 509 + [0] * 509\n",
    "# convert to array and check shape\n",
    "y = np.array(y,)\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-blood",
   "metadata": {},
   "source": [
    "### Train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "computational-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unexpected-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = X_train.astype('float32')\n",
    "# # X_test = X_test.astype('float32')\n",
    "\n",
    "# X_train = X_train / 255\n",
    "# X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "educated-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)#.reshape(1499, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "different-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)#.reshape(500, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "clinical-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 348, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "natural-legislation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-zoning",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "A CNN with three types of layers:\n",
    "\n",
    "- Convolutional Layer\n",
    "- Pooling Layer\n",
    "- Densely Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "unexpected-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = (348, 348, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Add another:\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "freelance-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 [==============================] - 79s 6s/step - loss: 2.3155 - accuracy: 0.5216 - val_loss: 0.6852 - val_accuracy: 0.6275\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 70s 6s/step - loss: 0.6801 - accuracy: 0.6671 - val_loss: 1.1345 - val_accuracy: 0.5176\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 69s 6s/step - loss: 0.7410 - accuracy: 0.5491 - val_loss: 0.6852 - val_accuracy: 0.6157\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 69s 6s/step - loss: 0.6372 - accuracy: 0.6579 - val_loss: 0.7905 - val_accuracy: 0.5020\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 69s 6s/step - loss: 0.5315 - accuracy: 0.7379 - val_loss: 0.5406 - val_accuracy: 0.7020\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lonely-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 346, 346, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 173, 173, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 171, 171, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 85, 85, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 462400)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                29593664  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,632,449\n",
      "Trainable params: 29,632,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
